---
title: 2011 Workshop/Day 1 Breakouts
layout: default
---
# 2011 Workshop/Day 1 Breakouts

## Wed, May 18, 2011, Break-out groups  

See also notes on [report-out Etherpad](http://piratepad.net/collabsci-wed-reportout.html) 

Break-out group 1: Questions

* Shouldn't be dictating the science
* Should not be so easy to lose the understanding of what is going on
* Controversy between too few and too many methods for the same probles; need to allow for diversity, yet poor methods need to die out

Break-out group 3:

1. Raw and derived data
2. Provenance data
3. Reports, tables, graphs
4. Observational data with semantically rich metadata
5. Workflows
6. Source code, ideally with source code
7. Theory and assumptions

* All are really necessary, so can't really choose - this is more w.r.t. a CI feature roll-out timetable
* There was a lot more discussion but the above came out as priority based on voting
* Provenance and what is the boundary between data and metadata
* Should have more robust archive for the things above.
* This may really be multiple CIs rather than one
* Minimum requirement should be the reusability of the data (or methods). So archiving requirements should be stated in that context. Data being available does not imply that one can reuse it.
* Could extract workflow from publications, but raw data are lost, impossible to extract.

### **Group 1: Low barriers to entry and Fitting CI to the Science**  

Two over-arching themes: 

1. Good CI development is all about striking the right balance 
2. CI provides a landscape but does not dictate specific tools / methods

Four main topics emerged from the brainstorming: 

* Lowering barriers 
  * can be both technical and cultural 
  * provide adaptable interfaces 
  * to users and developers 
*Redundant diversity 
  * avoid monoculture 
  * not reinvent the wheel 
  * avoid oversimplification 
  * benefits to diversity of tools 
  * efficiency 
  * discoverability of existing tools 
* Diverse Technical Skills 
  * user and development community very diverse 
  * CI should allow people to learn and become more technical 
  * should not force people to become technical 
  * customization vs standardization 
* Verification and validation 
  * of software / code 
  * of data 
  * overhead for reviewing 
  * required for re-use 
  * needs appropriate metadata

Notes from following discussion: 

* Shouldn't be dictating the science 
* Should not be so easy to lose the understanding of what is going on 
* Controversy between too few and too many methods for the same problems; need to allow for diversity, yet poor methods need to die out

### Group 2: Incentivizing 

#### **Challenges**  

(Ordered by group rankings) 

[May18-breakouts-group2-summary1](File-May18-breakouts-group2-summary1.jpg)
[May18-breakouts-group2-summary2.jpg](File-May18-breakouts-group2-summary2.jpg)

1. Risk aversion 
  * Loss of control 
  * Extended timeline to products 
  * People not carrying their weight in a collaboration 
2. Mapping to existing reward schemes 
  * Publications, grants =&gt; tenure track positions 
3. Understanding the "market" or target audience 
  *Basic user needs 
4. Few training opportunities / career path for non-PI positions 
5. Perception that the contribution is not permement 
  *Related to the need for long-term maintenance of CI resources 
6. Technology adoption barriers 
7. Understanding classes of users 
8. Conveying purpose 
9. Knowing what CI is available 
10. Changing people's perception

#### Opportunities  

(Ordered by group rankings) 

[May18-breakouts-group2-summary3.jpg](File-May18-breakouts-group2-summary3.jpg)
[May18-breakouts-group2-summary4.jpg](File-May18-breakouts-group2-summary4.jpg)

* Reward risk-taking 
  * Expand what we define as success and credit in the academic setting 
  * Recognition Badges in CI world 
* Aligning CI with Grand Challenge question 
* Use commercial resources and products when appropriate 
  * Use what works 
* Make people's lives easier 
  * Faster, better simpler 
* Including scientists from the onset 
* Expand role of peer review based on shift to digital publication 
* Streamlining publication process

#### Group discussion notes  

* Linking publication with data deposition, dissemination, standardization, and cyberinfrastructure.

#### Raw flipchart notes 
[May18-breakouts-group2-notes1.jpg](File-May18-breakouts-group2-notes1.jpg)
[May18-breakouts-group2-notes2.jpg](File-May18-breakouts-group2-notes2.jpg)
[May18-breakouts-group2-notes3.jpg](File-May18-breakouts-group2-notes3.jpg)
[May18-breakouts-group2-notes4.jpg](File-May18-breakouts-group2-notes4.jpg)

### Group 3: Products and processes of scientific research that need to be shared  

Participants:John Parker, Carole;Palmer, Eric Carr, Mark Schildhauer 

[Image:May18-breakouts-group3-summary1.jpg](May18-breakouts-group3-summary1.jpg)

 Prioritized summary: 

1. Raw and derived data 
2. Provenance information 
3. Reports, tables, graphs associated with published analysis 
4. Observational data with semantically rich metadata 
5. Workflows and source code, ideally with executable 
6. Theory and assumptions

Notes from ensuing discussion: 

* All are really necessary, so can't really choose - this is more w.r.t. a CI feature roll-out timetable 
* There was a lot more discussion but the above came out as priority based on voting 
* Provenance and what is the boundary between data and metadata 
* Should have more robust archive for the things above. 
* This may really be multiple CIs rather than one 
* Minimum requirement should be the reusability of the data (or methods). So archiving requirements should be stated in that context. Data being available does not imply that one can reuse it. 
* Could extract workflow from publications, but raw data are lost, impossible to extract.

### Group 4: Sustainability 

[SustainabilityWhiteBoard.jpg](File-SustainabilityWhiteBoard.jpg)

* Sustainability is a foundation for reaching many goals/outcomes including practicing new science, creating new knowledge, creating flexible infrastructure, and understanding/adjusting to changes in scientific understanding. 
* Funding is a key area of interest when discussing sustainability since it is important for CI longevity in all its aspects – the technology, the process, and the organization. 
* Another problem is that we, the CI community, haven’t agreed on a standardized model to discuss the future value of data which would be a guiding principle for CI development and management. 
  * We need to establish expectations, flexible interoperable systems, cyber infrastructure management best practices, funding models, and governance structures that are able to serve a diverse communities. 
* We also need to study relationship management and the roles of enabling partners. 
* The CI structures should allow quality data to rise to the top.

**GOALS &amp; OUTCOMES** - 1(vote as being of top three importance)

* Changes in scientific understanding 
* New knowledge
* New Science
* Creating flexible infrastructure 

**FUNDING** - 5

* Moving away from funding projects 
* Balancing cost against future value 
* Storage/migration funding (long-term commitment) 
* Leveraging projects (making funding go further)

**GOVERNANCE & Communication**- 1

* Governance models/structures
* Management change (challenge)
* Policies
* Legal issues
* Sustaining CI expertise (workforce availability)
* Strong message to external audience (can be created)
* Institutional incentives and responsibilities 

**PARTNERSHIPS/RELATIONSHIPS** -2

* Corporate/private partnership
* Diverse participation
* Building long-lived sustaining organizations
* Synthesis centers
* Value added by partnerships/relationships
* New relationships may be established (even beyond domains or traditional partners)
* Historical interest
* Role of libraries 

**SCOPE/GRANULARITY** - 1

* Bloat v Being inclusive
* Parallel development (can be good or bad depending on whether it is coordinated)
* Limited participation (a problem if not enough people buy-in)
* Too widely distributed network 

**COMMUNITY OF USERS**-1

* Life cycle triage
* Loss of interest (leads to weakening CI)
* Different users/different lifecycle
* Maintenance 

**ACCESS/VALIDATION** - 3

* Systems support
* Internet service hosting/access to computer resources
* Retraction process
* Do we keep it all?
* Don’t sustain it (opportunity to discuss retention schedules)
* Access
* Growth and longevity leads to better data validation 

**SYSTEMS** - 3

* Virtualization 
* Hardware independence 
* Exportable
* Server v. container standard format
* Integration
* Interoperability
* Archive workflow 

**DATA/PROCESS MANGEMENT** – 1 

* Saving useless if not reusable
* Tool migration/changes
* Legacy datasets
* Version control: Code versioning, tool versioning
* Data
* Reproducible
